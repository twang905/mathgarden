{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Model Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7jporBCjTqNH",
        "jhXcI9CFTqNK",
        "vJOYMe15TqNL",
        "TYWhjVvcTqNL",
        "QLXpD33ZTqNS"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvUwR4b7TqM7"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "galoVT64TqM-"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(888)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EchWbiiXTqM_"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from time import strftime\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJklNUtRTqNA"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vilCkwI4TqNA"
      },
      "source": [
        "X_TRAIN_PATH = 'Handwriting/digit_xtrain.csv'\n",
        "X_TEST_PATH = 'Handwriting/digit_xtest.csv'\n",
        "Y_TRAIN_PATH = 'Handwriting/digit_ytrain.csv'\n",
        "Y_TEST_PATH = 'Handwriting/digit_ytest.csv'\n",
        "\n",
        "LOGGING_PATH = 'tensorboard_Handwriting_logs/'\n",
        "\n",
        "NR_CLASSES = 10\n",
        "\n",
        "VALIDATION_SIZE = 10000\n",
        "\n",
        "IMAGE_WIDTH = 28\n",
        "IMAGE_HEIGHT = 28\n",
        "CHANNELS = 1\n",
        "\n",
        "TOTAL_INPUTS = IMAGE_WIDTH * IMAGE_HEIGHT * CHANNELS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HokIgogWTqNB"
      },
      "source": [
        "# Get the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHI8AGcvTqNC",
        "outputId": "bd7b4573-49ac-44e5-b20a-33b10ee9dfa6"
      },
      "source": [
        "%%time\n",
        "\n",
        "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter = ',', dtype = int)\n",
        "y_test = np.loadtxt(Y_TEST_PATH, delimiter = ',', dtype = int)\n",
        "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter = ',', dtype = int)\n",
        "x_test = np.loadtxt(X_TEST_PATH, delimiter = ',', dtype = int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 59.4 s, sys: 2.69 s, total: 1min 2s\n",
            "Wall time: 1min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReK9o0znTqND"
      },
      "source": [
        "# Explore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVSAhvrhTqND",
        "outputId": "323f5298-9e1f-4fe8-9dda-aa550b125571"
      },
      "source": [
        "x_train_all.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SOVB09XmTqNE",
        "outputId": "eac2406a-a8c9-4eba-d3af-e26c5896ca60"
      },
      "source": [
        "x_train_all[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BCYKkHBTqNE"
      },
      "source": [
        "# Proprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Zljn0_TqNF"
      },
      "source": [
        "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6dHoJaJTqNG"
      },
      "source": [
        "### Hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTdjkerpTqNG"
      },
      "source": [
        "y_train_all = np.eye(NR_CLASSES)[y_train_all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpAgrfh1TqNG"
      },
      "source": [
        "y_test = np.eye(NR_CLASSES)[y_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jporBCjTqNH"
      },
      "source": [
        "### Create validation dataset from training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSQSHUFTqNI"
      },
      "source": [
        "x_validation = x_train_all[:VALIDATION_SIZE]\n",
        "y_validation = y_train_all[:VALIDATION_SIZE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vmiVIkvTqNI"
      },
      "source": [
        "x_train = x_train_all[VALIDATION_SIZE:]\n",
        "y_train = y_train_all[VALIDATION_SIZE:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLK7cCyhTqNJ"
      },
      "source": [
        "# Setup Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh6ULMnZTqNJ"
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape = [None, 784], name= 'X')\n",
        "y = tf.placeholder(tf.float32, shape = [None, NR_CLASSES], name = 'labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtPZVvOoTqNJ"
      },
      "source": [
        "## Neural Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhXcI9CFTqNK"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r3HYvfrTqNK"
      },
      "source": [
        "nr_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj3GkvWwTqNK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJOYMe15TqNL"
      },
      "source": [
        "### Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE9KSqRJTqNL"
      },
      "source": [
        "# with tf.name_scope('first_layer'):\n",
        "\n",
        "#     initial_w1 = tf.truncated_normal(shape = [TOTAL_INPUTS, n_hidden1], stddev = 0.1, seed = 42)\n",
        "#     w1 = tf.Variable(initial_value = initial_w1, name = 'w1')\n",
        "\n",
        "#     initial_b1 = tf.constant(value = 0.0, shape = [n_hidden1])\n",
        "#     b1 = tf.Variable(initial_value = initial_b1, name = 'b1')\n",
        "\n",
        "#     layer1_in = tf.matmul(x, w1) + b1\n",
        "#     layer1_out = tf.nn.relu(layer1_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYWhjVvcTqNL"
      },
      "source": [
        "### Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlZU67zKTqNM"
      },
      "source": [
        "# with tf.name_scope('second_layer'):\n",
        "\n",
        "#     initial_w2 = tf.truncated_normal(shape = [n_hidden1, n_hidden2], stddev = 0.1, seed = 42)\n",
        "#     w2 = tf.Variable(initial_value = initial_w2, name = 'w2')\n",
        "\n",
        "#     initial_b2 = tf.constant(value = 0.0, shape = [n_hidden2])\n",
        "#     b2 = tf.Variable(initial_value = initial_b2, name = 'b2')\n",
        "\n",
        "#     layer2_in = tf.matmul(layer1_out, w2) + b2\n",
        "#     layer2_out = tf.nn.relu(layer2_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc8Ky-dwTqNM"
      },
      "source": [
        "### Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L472JyCjTqNN"
      },
      "source": [
        "# with tf.name_scope('output_layer'):\n",
        "\n",
        "#     initial_w3 = tf.truncated_normal(shape = [n_hidden2, NR_CLASSES], stddev = 0.1, seed = 42)\n",
        "#     w3 = tf.Variable(initial_value = initial_w3, name = 'w3')\n",
        "\n",
        "#     initial_b3 = tf.constant(value = 0.0, shape = [NR_CLASSES])\n",
        "#     b3 = tf.Variable(initial_value = initial_b3, name = 'b3')\n",
        "\n",
        "#     layer3_in = tf.matmul(layer2_out, w3) + b3\n",
        "#     output = tf.nn.softmax(layer3_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNUeuGXhTqNN"
      },
      "source": [
        "def setup_layer(input, weight_dim, bias_dim, name):\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "\n",
        "        initial_w = tf.truncated_normal(shape = weight_dim, stddev = 0.1, seed = 42)\n",
        "        w = tf.Variable(initial_value = initial_w, name = 'W')\n",
        "\n",
        "        initial_b = tf.constant(value = 0.0, shape = bias_dim)\n",
        "        b = tf.Variable(initial_value = initial_b, name = 'B')\n",
        "\n",
        "        layer_in = tf.matmul(input, w) + b\n",
        "        \n",
        "        if name == 'out':\n",
        "            \n",
        "            layer_out = tf.nn.softmax(layer_in)\n",
        "            \n",
        "        else:\n",
        "            \n",
        "            layer_out = tf.nn.relu(layer_in)\n",
        "            \n",
        "        tf.summary.histogram('weights', w)\n",
        "        tf.summary.histogram('biases', b)\n",
        "            \n",
        "        return layer_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXqCEDSTTqNO"
      },
      "source": [
        "layer_1 = setup_layer(x, weight_dim = [TOTAL_INPUTS, n_hidden1], bias_dim = [n_hidden1], name = 'layer_1')\n",
        "\n",
        "layer_drop = tf.nn.dropout(layer_1, keep_prob = 0.8, name = 'dropout_layer')\n",
        "\n",
        "layer_2 = setup_layer(\n",
        "    layer_drop, weight_dim = [n_hidden1, n_hidden2], \n",
        "    bias_dim = [n_hidden2], name = 'layer_2')\n",
        "\n",
        "output = setup_layer(\n",
        "    layer_2, weight_dim = [n_hidden2, NR_CLASSES], \n",
        "    bias_dim = [NR_CLASSES], name = 'out')\n",
        "\n",
        "model_name = f'{n_hidden1}-DO-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxJ9AYI_TqNO"
      },
      "source": [
        "# Tensorboard setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwEF6c5FTqNO",
        "outputId": "4dbaeb25-aac4-4141-ad6f-117d8c5e3e54"
      },
      "source": [
        "folder_name = f'Model 1 at {strftime(\"%H:%M\")}'\n",
        "directory = os.path.join(LOGGING_PATH, folder_name)\n",
        "\n",
        "try:\n",
        "    os.makedirs(directory)\n",
        "except OSError as exception:\n",
        "    print(exception.strerror)\n",
        "else:\n",
        "    print('Successfully created directories!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created directories!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX8-ltUlTqNP"
      },
      "source": [
        "# Loss, Optimization & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhsMO3YcTqNQ"
      },
      "source": [
        "with tf.name_scope('loss_calc'):\n",
        "    \n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = output))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG0zmFy0TqNQ"
      },
      "source": [
        "with tf.name_scope('optimizer'):\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    train_step = optimizer.minimize(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jLk8TFqTqNR"
      },
      "source": [
        "## Accuracy Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta2La72-TqNR"
      },
      "source": [
        "with tf.name_scope('accuracy_metric'):\n",
        "    correct_pred = tf.equal(tf.argmax(output, axis = 1), tf.argmax(y, axis = 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGTCB7eQTqNR"
      },
      "source": [
        "with tf.name_scope('performance'):\n",
        "    tf.summary.scalar('accuracy', accuracy)\n",
        "    tf.summary.scalar('loss', loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLXpD33ZTqNS"
      },
      "source": [
        "### Check Input images in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znz0LgYbTqNS"
      },
      "source": [
        "with tf.name_scope('show_image'): \n",
        "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "    tf.summary.image('image_input', x_image, max_outputs=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qHsH0s6TqNS"
      },
      "source": [
        "# Run Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQOxGHpTqNS"
      },
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drgynS2GTqNT"
      },
      "source": [
        "## Setup Filewrite and Merge Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8usepEoGTqNT"
      },
      "source": [
        "merged_summary = tf.summary.merge_all()\n",
        "\n",
        "train_writer = tf.summary.FileWriter(directory + '/train')\n",
        "train_writer.add_graph(sess.graph)\n",
        "\n",
        "\n",
        "validation_writer = tf.summary.FileWriter(directory + '/validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KhQbu2_TqNT"
      },
      "source": [
        "## Initialise all variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMucXdWFTqNT"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-86EaoCfTqNU"
      },
      "source": [
        "# b3.eval(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOq65uIRTqNU"
      },
      "source": [
        "## Batching the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2J5f5mJTqNU"
      },
      "source": [
        "size_of_batch = 1000\n",
        "\n",
        "num_examples = y_train.shape[0]\n",
        "nr_iterations = int(num_examples/size_of_batch)\n",
        "\n",
        "index_in_epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJDIjstXTqNU"
      },
      "source": [
        "def next_batch(batch_size, data, labels):\n",
        "    \n",
        "    global num_examples\n",
        "    global index_in_epoch\n",
        "    \n",
        "    start = index_in_epoch\n",
        "    index_in_epoch += batch_size\n",
        "    \n",
        "    if index_in_epoch > num_examples:\n",
        "        start = 0\n",
        "        index_in_epoch = batch_size\n",
        "        \n",
        "    end = index_in_epoch\n",
        "    \n",
        "    return data[start:end], labels[start:end]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyiiL4u8TqNV"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACiX1uHtTqNV",
        "outputId": "62621a6d-6929-4ccf-eb03-7974c1b831fa"
      },
      "source": [
        "for epoch in range(nr_epochs):\n",
        "    \n",
        "    for i in range(nr_iterations):\n",
        "        \n",
        "        batch_x, batch_y = next_batch(batch_size = size_of_batch, data = x_train, labels = y_train)\n",
        "        \n",
        "        feed_dictionary = {x:batch_x, y:batch_y}\n",
        "        \n",
        "        sess.run(train_step, feed_dict = feed_dictionary)\n",
        "        \n",
        "    \n",
        "    s, batch_accuracy = sess.run(fetches = [merged_summary, accuracy], feed_dict = feed_dictionary)\n",
        "        \n",
        "    train_writer.add_summary(s, epoch)\n",
        "    \n",
        "    print(f'Epoch {epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
        "    \n",
        "    ## validation\n",
        "    \n",
        "    summary = sess.run(fetches=merged_summary, feed_dict = {x:x_validation, y:y_validation})\n",
        "    validation_writer.add_summary(summary, epoch)\n",
        "\n",
        "print('Done training.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 \t| Training Accuracy = 0.8489999771118164\n",
            "Epoch 1 \t| Training Accuracy = 0.8579999804496765\n",
            "Epoch 2 \t| Training Accuracy = 0.8659999966621399\n",
            "Epoch 3 \t| Training Accuracy = 0.8669999837875366\n",
            "Epoch 4 \t| Training Accuracy = 0.8690000176429749\n",
            "Epoch 5 \t| Training Accuracy = 0.8759999871253967\n",
            "Epoch 6 \t| Training Accuracy = 0.9769999980926514\n",
            "Epoch 7 \t| Training Accuracy = 0.9769999980926514\n",
            "Epoch 8 \t| Training Accuracy = 0.9779999852180481\n",
            "Epoch 9 \t| Training Accuracy = 0.9829999804496765\n",
            "Done training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuJS_ZKLTqNW"
      },
      "source": [
        "# Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUBwxM0mTqNW",
        "outputId": "acf5ddcf-c18c-45be-9777-8bc063b0e863"
      },
      "source": [
        "img = Image.open('Handwriting/test_img.png')\n",
        "img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABAElEQVR4nO2Vyw2DMAyG3ap3RoAVmMCBrXICbwIbMEEEmzBCmMA9VFR9EGLTqhIV3xET/vjHjxMzM/yQ8y/FDsEgRAREtEnwJC2aWWAYhqfnzjmVoChDIroLISI45+5C2kwvsRemaYK+76HrOkiS5CmGiG8ZR2EB4zgGY0VRcF3Xks8wM7PI0jRNgzFEVCW4j7b4CLH5C3jv2RjD3nvxmWiVhphbJc/zt+pdY5NgWZYAcCuYqqp0hzUWWmvZGMPWWrX9KksfJ03TNKttEmNV8HWkqe1bIDi8iQjatoUsy8TNLbnQ6rbQDObZiej22Pz3F5DMVPE+/Bb/P0sPwf0LXgGAJwNqzP5nHgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28 at 0x7FDE12EAF910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82p7_tDxTqNW"
      },
      "source": [
        "bw = img.convert('L')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM5-9OrlTqNX"
      },
      "source": [
        "image_array = np.invert(bw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-YQOODiTqNX"
      },
      "source": [
        "test_img = image_array.ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4iiUkbiTqNX",
        "outputId": "4aad245f-f2e8-4af1-de7d-f09fc0e55abc"
      },
      "source": [
        "prediction = sess.run(fetches = tf.argmax(output, axis = 1), feed_dict = {x: [test_img]})\n",
        "print(f'Prediction is: {prediction}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction is: [2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQlNDXNzTqNX",
        "outputId": "621c15a4-bf11-4007-ae88-13810e8bee16"
      },
      "source": [
        "test_accuracy = sess.run(fetches = accuracy, feed_dict = {x:x_test, y:y_test})\n",
        "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set is 96.41%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjBIzUSXTqNY"
      },
      "source": [
        "# Reset for next run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y43BIWT6TqNY"
      },
      "source": [
        "train_writer.close()\n",
        "sess.close()\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxF8gvMKTqNY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}